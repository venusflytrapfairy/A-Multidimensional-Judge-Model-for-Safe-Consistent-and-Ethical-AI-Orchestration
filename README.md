# A-Multidimensional-Judge-Model-for-Safe-Consistent-and-Ethical-AI-Orchestration
For the Martian x Apart Research Routing Hackathon!
Overview
This repository contains the code and data for our project on evaluating the safety, consistency, and reliability of large language models (LLMs) and routing systems using a multidimensional safety judge. Our approach provides transparent, interpretable scoring on key safety dimensions and supports reproducible benchmarking of both monolithic and routed AI outputs.

# Contents
1. mainmartianjudge.ipynb:
The main Colab notebook containing all code to reproduce our judge model, run evaluations, and generate analysis/visualizations.

2. llm_benchmarks_dataset
The dataset of model and router responses, including scores for bias, factuality, manipulation resistance, toxicity, and other safety dimensions, as generated by our experiments.

# Quick Start
Open mainmartianjudge.ipynb in Google Colab

Run all cells to load the dataset, apply the multidimensional judge, and reproduce our analysis and plots.

# Explore the Dataset

The llm_benchmarks_dataset file contains all evaluated responses and their safety scores for further analysis or custom experiments.

# Features
Multidimensional Safety Judge:
Independently scores each output for bias, factuality, manipulation resistance, and toxicity.

# Transparent Evaluation:
All scoring criteria and prompt templates are documented in the notebook for full interpretability.

# Reproducible Analysis:
Includes code for statistical analysis and visualizations (boxplots, radar charts, heatmaps) to compare model and router performance.

# Requirements
1. Python (Colab environment recommended)

2. pandas, numpy, seaborn, matplotlib

3. Access to Martian API or pre-generated response data
